/**
 * llms_txt2ctx format parser
 *
 * Parses the llms_txt2ctx style format: `<doc title="..." desc="...">content</doc>`
 * Generated by the `llms_txt2ctx` CLI from the llms-txt package (https://github.com/AnswerDotAI/llms-txt).
 * Used by fastht.ml and similar projects.
 *
 * For example: https://fastht.ml/docs/llms-ctx-full.txt
 */

import type { Page, StreamingParser } from "../types.ts";
import type { ClosingTagToken, OpeningTagToken } from "../utils/tokenize.ts";
import { tokenize } from "../utils/tokenize.ts";

/**
 * Streaming parser for llms_txt2ctx format using tokenizer
 */
export class LlmsTxt2ctxStreamingParser implements StreamingParser {
  /**
   * Detect if the content matches llms_txt2ctx format
   */
  public static detect(lines: string[]): "certain" | "maybe" | "no" {
    if (!lines.findLast((line) => line.includes("</doc"))) {
      // It does not contain a closing doc tag
      return "no";
    }
    const content = lines.join("\n");

    const openTags: OpeningTagToken[] = [];
    const closeTags: ClosingTagToken[] = [];
    for (const token of tokenize(content)) {
      if (token.type === "openTag" && token.name === "doc") {
        // Found opening doc tag
        if (!token.selfClosing) {
          openTags.push(token);
        }
      } else if (token.type === "closeTag" && token.name === "doc") {
        // Found closing doc tag
        closeTags.push(token);
      }
      if (openTags.length > 0 && openTags.length === closeTags.length) {
        return "certain";
      }
    }

    return "no";
  }

  private input = "";

  /**
   * Process final content in buffer
   */
  public *flush(): Generator<Page> {
    for (const { page } of this.processContent(this.input)) {
      yield page;
    }
  }

  /**
   * Append line to the buffer
   */
  public *appendLine(line: string): Generator<Page> {
    this.input += `${line}\n`;
    if (!line.includes("</doc")) return;

    let nextIndex = 0;
    for (const processed of this.processContent(this.input)) {
      yield processed.page;
      nextIndex = processed.nextIndex;
    }
    this.input = this.input.slice(nextIndex);
  }

  /**
   * Process content and yield complete pages using tokenizer
   */
  private *processContent(
    input: string,
  ): Generator<{ page: Page; nextIndex: number }> {
    type OpenTagStack = {
      token: OpeningTagToken;
      parent?: OpenTagStack | null;
    };
    let openTagStack: OpenTagStack | null = null;
    for (const token of tokenize(input)) {
      if (
        token.type === "openTag" &&
        !token.selfClosing &&
        token.name === "doc"
      ) {
        openTagStack = { token, parent: openTagStack };
      } else if (
        token.type === "closeTag" &&
        token.name === "doc" &&
        openTagStack != null
      ) {
        if (openTagStack.parent == null) {
          // Found a complete doc tag
          const content = input
            .slice(openTagStack.token.range.end, token.range.start)
            .trim();
          yield {
            page: {
              title:
                typeof openTagStack.token.attrs.title === "string"
                  ? openTagStack.token.attrs.title
                  : null,
              content,
              metadata: openTagStack.token.attrs,
            },
            nextIndex: token.range.end,
          };
        }
        openTagStack = openTagStack.parent ?? null;
      }
    }
  }
}
